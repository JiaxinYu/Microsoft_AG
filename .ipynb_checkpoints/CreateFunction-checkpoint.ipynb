{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Affiliations(rootpath):\n",
    "    Affiliations = spark.read.load(rootpath + \"Affiliations.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    "    .toDF(\"AffiliationId\", \"Rank\", \"NormalizedName\", \"DisplayName\", \"GridId\", \"OfficialPage\", \"WikiPage\", \"PaperCount\", \"CitationCount\", \n",
    "      \"CreatedDate\")\n",
    "    return Affiliations\n",
    "\n",
    "\n",
    "def Authors(rootpath): \n",
    "    Authors = spark.read.load(rootpath + \"Authors.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    "    .toDF(\"AuthorId\", \"Rank\", \"NormalizedName\", \"DisplayName\", \"LastKnownAffiliationId\", \"PaperCount\", \"CitationCount\", \"CreatedDate\")\n",
    "    return Authors\n",
    "\n",
    "\n",
    "def ConferenceSeries(rootpath):\n",
    "    ConferenceSeries = spark.read.load(rootpath + \"ConferenceSeries.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    "    .toDF(\"ConferenceSeriesId\", \"Rank\", \"NormalizedName\", \"DisplayName\", \"PaperCount\", \"CitationCount\", \"CreatedDate\")\n",
    "    return ConferenceSeries\n",
    "\n",
    "\n",
    "def FieldsOfStudy(rootpath): \n",
    "    FieldsOfStudy = spark.read.load(rootpath + \"FieldsOfStudy.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    "    .toDF(\"FieldOfStudyId\", \"Rank\", \"NormalizedName\", \"DisplayName\", \"MainType\", \"Level\", \"PaperCount\", \"CitationCount\", \"CreatedDate\")\n",
    "    return FieldsOfStudy\n",
    "\n",
    "\n",
    "def Journals(rootpath): \n",
    "    Journals = spark.read.load(rootpath + \"Journals.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    "    .toDF(\"JournalId\", \"Rank\", \"NormalizedName\", \"DisplayName\", \"Issn\", \"Publisher\", \"Webpage\", \"PaperCount\", \"CitationCount\", \"CreatedDate\")\n",
    "    return Journals\n",
    "\n",
    "\n",
    "def Papers(rootpath): \n",
    "    Papers = spark.read.load(rootpath + \"Papers.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    "    .toDF(\"PaperId\", \"Rank\", \"Doi\", \"DocType\", \"PaperTitle\", \"OriginalTitle\", \"BookTitle\", \"Year\", \"Date\", \"Publisher\", \"JournalId\", \n",
    "          \"ConferenceSeriesId\", \"ConferenceInstanceId\", \"Volume\", \"Issue\", \"FirstPage\", \"LastPage\", \"ReferenceCount\", \"CitationCount\", \n",
    "          \"EstimatedCitationCount\", \"CreatedDate\")\n",
    "    return Papers\n",
    "\n",
    "\n",
    "def PaperAuthorAffiliations(rootpath):\n",
    "    PaperAuthorAffiliations = spark.read.load(rootpath + \"PaperAuthorAffiliations.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    "    .toDF(\"PaperId\", \"AuthorId\", \"AffiliationId\", \"AuthorSequenceNumber\", \"OriginalAffiliation\")\n",
    "    return PaperAuthorAffiliations\n",
    "\n",
    "\n",
    "def PaperFieldsOfStudy(rootpath): \n",
    "    PaperFieldsOfStudy = spark.read.load(rootpath + \"PaperFieldsOfStudy.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    "    .toDF(\"PaperId\", \"FieldOfStudyId\", \"Score\")\n",
    "    return PaperFieldsOfStudy\n",
    "\n",
    "\n",
    "def PaperReferences(rootpath):\n",
    "    PaperReferences = spark.read.load(rootpath + \"PaperReferences.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    "    .toDF(\"PaperId\", \"PaperReferenceId\")\n",
    "    return PaperReferences\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
