{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Organization Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as sf\n",
    "\n",
    "\n",
    "rootpath = 'wasbs://mag-2018-09-27@magtrainingsource.blob.core.windows.net/mag/'\n",
    "outputDir = '/output/user99/pyspark/'\n",
    "organizationName = 'microsoft'\n",
    "organizationPaperMinYear = 1991\n",
    "maDetailPagePrefix = 'https://academic.microsoft.com/#/detail/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the affiliation for the input organization\n",
    "Affiliations = spark.read.load(rootpath + \"Affiliations.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    ".toDF(\"AffiliationId\", \"Rank\", \"NormalizedName\", \"DisplayName\", \"GridId\", \"OfficialPage\", \"WikiPage\", \"PaperCount\", \"CitationCount\", \n",
    "      \"CreatedDate\")\n",
    "\n",
    "targetAffiliation = Affiliations.where(sf.col(\"NormalizedName\").isin(organizationName)) \\\n",
    ".selectExpr(\"AffiliationId\", \"DisplayName as AffiliationName\")\n",
    "\n",
    "targetAffiliation.write.csv(outputDir + \"targetAffiliation.csv\", mode='overwrite', header='true')\n",
    "\n",
    "targetAffiliationId = targetAffiliation.select(\"AffiliationId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all [Paper]->[Author]->[Affiliation(input organization] relationships\n",
    "PaperAuthorAffiliations = spark.read.load(rootpath + \"PaperAuthorAffiliations.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    ".toDF(\"PaperId\", \"AuthorId\", \"AffiliationId\", \"AuthorSequenceNumber\", \"OriginalAffiliation\") \n",
    "\n",
    "orgPaperAuthorAffiliation = PaperAuthorAffiliations.join(targetAffiliationId, \"AffiliationId\", 'inner') \\\n",
    ".select(\"PaperId\", \"PaperId\", \"AffiliationId\", \"AuthorSequenceNumber\")\n",
    "\n",
    "orgPaperAuthorAffiliation.write.csv(outputDir + \"orgPaperAuthorAffiliation.csv\", mode='overwrite', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all org author details\n",
    "Authors = spark.read.load(rootpath + \"Authors.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    ".toDF(\"AuthorId\", \"Rank\", \"NormalizedName\", \"DisplayName\", \"LastKnownAffiliationId\", \"PaperCount\", \"CitationCount\", \"CreatedDate\")\n",
    "\n",
    "orgAuthors = Authors.join(orgAuthorIds, \"AuthorId\", 'inner') \\\n",
    ".selectExpr(\"AuthorId\", \"DisplayName as AuthorName\")\n",
    "\n",
    "orgAuthors.write.csv(outputDir + \"orgAuthors.csv\", mode='overwrite', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all paper Ids for the input organization\n",
    "orgPaperIds = orgPaperAuthorAffiliation.select(\"PaperId\").distinct()\n",
    "\n",
    "\n",
    "# Get all org paper details\n",
    "Papers = spark.read.load(rootpath + \"Papers.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    ".toDF(\"PaperId\", \"Rank\", \"Doi\", \"DocType\", \"PaperTitle\", \"OriginalTitle\", \"BookTitle\", \"Year\", \"Date\", \"Publisher\", \"JournalId\", \n",
    "      \"ConferenceSeriesId\", \"ConferenceInstanceId\", \"Volume\", \"Issue\", \"FirstPage\", \"LastPage\", \"ReferenceCount\", \"CitationCount\", \n",
    "      \"EstimatedCitationCount\", \"CreatedDate\")\n",
    "\n",
    "orgPapers = Papers.join(orgPaperIds, \"PaperId\", 'inner') \\\n",
    ".where(\"Year\" >= organizationPaperMinYear) \\\n",
    ".selectExpr(\"PaperId\", \"PaperTitle as Title\", \"EstimatedCitation as CitationCount\", \"Date\", \"\")\n",
    "# @orgPapers =\n",
    "#     SELECT Papers.PaperId,\n",
    "#            Papers.PaperTitle AS Title,\n",
    "#            Papers.EstimatedCitation AS CitationCount,\n",
    "#            Papers.Date,\n",
    "#            //Use \"Not avaliable\" to represent the publication type if it is unknown.\n",
    "#            String.IsNullOrEmpty(Papers.DocType) ? \"Not avaliable\" : Papers.DocType AS PublicationType,\n",
    "#            Math.Exp(Papers.Rank * -0.001) AS LogProb,\n",
    "#            @maDetailPagePrefix + Papers.PaperId AS Url,\n",
    "#            Papers.ConferenceSeriesId == null ? Papers.JournalId : Papers.ConferenceSeriesId AS VId,\n",
    "#            Year\n",
    "#     FROM Papers\n",
    "#          INNER JOIN\n",
    "#              @orgPaperIds\n",
    "#          ON Papers.PaperId == @orgPaperIds.PaperId\n",
    "#     WHERE Year >= @organizationPaperMinYear;\n",
    "orgPapers.write.csv(outputDir + \"orgPapers.csv\", mode='overwrite', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all [Paper]->[Author/Affiliation] relationships for the org\n",
    "orgAllPaperAuthorAffiliations = PaperAuthorAffiliations.join(orgPapers, \"PaperId\", 'inner') \\\n",
    ".select(\"PaperId\", \"AuthorId\", \"AffiliationId\", \"AuthorSequenceNumber\")\n",
    "\n",
    "\n",
    "# All distinct affiliation id from [Paper] -> [Author/Affiliation] relationship are the partner affiliations\n",
    "orgPartnerPaperAuthorAffiliations = orgPaperAuthorAffiliation.exceptAll(orgAllPaperAuthorAffiliations)\n",
    "\n",
    "orgPartnerPaperAuthorAffiliations.write.csv(outputDir + \"orgPartnerPaperAuthorAffiliations.csv\", mode='overwrite', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all partner orgs' affiliation Ids\n",
    "orgPartnerAffiliationIds = orgPartnerPaperAuthorAffiliations.where(sf.col(\"AffiliationId\").isnotnull()) \\\n",
    ".select(\"AffiliationId\").distinct()\n",
    "\n",
    "\n",
    "# Get all partner orgs' affiliation details\n",
    "orgPartnerAffiliations = Affiliations.join(orgPartnerAffiliationIds, \"AffiliationId\", 'inner') \\\n",
    ".selectExpr(\"AffiliationId\", \"DisplayName as AffiliationName\")\n",
    "\n",
    "orgPartnerAffiliations.write.csv(outputDir + \"orgPartnerAffiliations.csv\", mode='overwrite', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all partner authors' Ids\n",
    "orgPartnerAuthorIds = orgPartnerPaperAuthorAffiliations.select(\"AuthorId\").distinct()\n",
    "\n",
    "\n",
    "#Get all partner authors' details\n",
    "orgPartnerAuthors = Authors.join(orgPartnerAuthorIds, \"AuthorId\", 'inner') \\\n",
    ".selectExpr(\"AuthorId\", \"DisplayName as AuthorName\")\n",
    "\n",
    "orgPartnerAuthors.write.csv(outputDir + \"orgPartnerAuthors.csv\", mode='overwrite', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all [Paper]->[Field of Study] relationships for the input organization\n",
    "PaperFieldsOfStudy = spark.read.load(rootpath + \"PaperFieldsOfStudy.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    ".toDF(\"PaperId\", \"FieldOfStudyId\", \"Score\")\n",
    "\n",
    "orgPaperFieldOfStudy = PaperFieldsOfStudy.join(orgPapers, \"PaperId\", 'inner') \\\n",
    ".select(\"PaperId\", \"FieldOfStudyId\")\n",
    "\n",
    "orgPaperFieldOfStudy.write.csv(outputDir + \"orgPaperFieldOfStudy.csv\", mode='overwrite', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all Field of Study Ids for the input organization\n",
    "orgFieldOfStudyIds = orgPaperFieldOfStudy.select(\"FieldOfStudyId\").distinct()\n",
    "\n",
    "\n",
    "# Get all fields of study details for the input organization\n",
    "FieldsOfStudy = spark.read.load(rootpath + \"FieldsOfStudy.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    ".toDF(\"FieldOfStudyId\", \"Rank\", \"NormalizedName\", \"DisplayName\", \"MainType\", \"Level\", \"PaperCount\", \"CitationCount\", \"CreatedDate\")\n",
    "\n",
    "fieldOfStudyOut = FieldsOfStudy.join(orgFieldOfStudyIds, \"FieldOfStudyId\", 'inner') \\\n",
    ".selectExpr(\"FieldOfStudyId\", \"Level as FieldLevel\", \"DisplayName as FieldName\")\n",
    "\n",
    "fieldOfStudyOut.write.csv(outputDir + \"fieldOfStudyOut.csv\", mode='overwrite', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all Conference/Journal details as Venue details\n",
    "venue = Journals.selectExpr(\"JournalId as VId\", \"DisplayName as VenueName\", \"NormalizedName as VenueShortName\") \\\n",
    ".union(ConferenceSeries.selectExpr(\"ConferenceSeriesId as VId\", \"DisplayName as VenueName\", \"NormalizedName as VenueShortName\"))\n",
    "\n",
    "venue.write.csv(outputDir + \"venue.csv\", mode='overwrite', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
