{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Field of Study Top Authors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, desc\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "rootpath = 'wasbs://mag-2018-09-27@magtrainingsource.blob.core.windows.net/mag/'\n",
    "outputDir = '/output/jiaxin/pyspark/'\n",
    "targetFoS = 'computer science'\n",
    "n_top = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark context\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "\n",
    "# load data\n",
    "_FieldsOfStudy = spark.read.load(rootpath + \"FieldsOfStudy.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    ".toDF(\"FieldOfStudyId\", \"Rank\", \"NormalizedName\", \"DisplayName\", \"MainType\", \n",
    "      \"Level\", \"PaperCount\", \"CitationCount\", \"CreatedDate\") \\\n",
    ".where(col(\"NormalizedName\").isin(targetFoS)) \\\n",
    ".select(\"FieldOfStudyId\")\n",
    "\n",
    "\n",
    "# Get all paperIds for the field\n",
    "_PaperFieldsOfStudy = spark.read.load(rootpath + \"PaperFieldsOfStudy.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    ".toDF(\"PaperId\", \"FieldOfStudyId\", \"Score\") \\\n",
    ".join(_FieldsOfStudy, \"FieldOfStudyId\", 'inner') \\\n",
    ".select(\"PaperId\")\n",
    "\n",
    "\n",
    "# Get all [citing paper] -> [field paper] relationships\n",
    "_PaperReferences = spark.read.load(rootpath + \"PaperReferences.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    ".toDF(\"PaperId\", \"PaperReferenceId\") \\\n",
    ".groupby(\"PaperReferenceId\") \\\n",
    ".count() \\\n",
    ".selectExpr(\"PaperReferenceId as PaperId\", \"count as CitationCount\")\n",
    "\n",
    "\n",
    "# For each field paper, count incoming reference to get citation count\n",
    "_ReferencesCount = _PaperReferences.join(_PaperFieldsOfStudy, \"PaperId\", 'inner')\n",
    "\n",
    "\n",
    "# Join against PaperAuthorAffiliation to get field paper -> field author relationship\n",
    "_paperauthoraffiliation = spark.read.load(rootpath + \"PaperAuthorAffiliations.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    ".toDF(\"PaperId\", \"AuthorId\", \"AffiliationId\", \"AuthorSequenceNumber\", \"OriginalAffiliation\") \\\n",
    ".join(_ReferencesCount, \"PaperId\", 'inner') \\\n",
    ".select(\"AuthorId\", \"PaperId\", \"CitationCount\")\n",
    "\n",
    "\n",
    "# Then join against Author to get detail author information\n",
    "# Aggregate over authorId to cacluate publication/ciation count for each author\n",
    "_Authors = spark.read.load(rootpath + \"Authors.txt\", format=\"csv\", sep=\"\\t\") \\\n",
    ".toDF(\"AuthorId\", \"Rank\", \"NormalizedName\", \"DisplayName\", \"LastKnownAffiliationId\", \n",
    "      \"PaperCount\", \"CitationCount\", \"CreatedDate\") \\\n",
    ".join(_paperauthoraffiliation, \"AuthorId\", 'inner') \\\n",
    ".groupby(\"AuthorId\") \\\n",
    ".count() \\\n",
    ".selectExpr(\"AuthorId as AuthorId\", \"DisplayName as Name\", \"CitationCount as CitationCount\", \"count as PublicationCount\")\n",
    "# .write.save(outputDir + \"Top_Authors.csv\", format=\"csv\", mode=\"overwrite\")\n",
    "\n",
    "\n",
    "# Get top n authors by citation count\n",
    "Fos_Authors = _Authors.sort(desc(\"CitationCount\"), desc(\"PublicationCount\")) \\\n",
    ".limit(n_top).show()\n",
    "\n",
    "\n",
    "# Stop Spark context\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
